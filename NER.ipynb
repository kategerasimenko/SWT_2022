{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parse texts"
      ],
      "metadata": {
        "id": "y8pLQNGSNKVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza\n",
        "!pip install lxml"
      ],
      "metadata": {
        "id": "PPPffisMNMHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os \n",
        "from collections import defaultdict\n",
        "from time import sleep\n",
        "from io import StringIO\n",
        "\n",
        "import requests\n",
        "import stanza\n",
        "from lxml import etree"
      ],
      "metadata": {
        "id": "rbRBJZWFNPgq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STANZA_OBJ = stanza.Pipeline(lang='es', processors='tokenize,ner')"
      ],
      "metadata": {
        "id": "gWbYdNLhNcPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API = 'https://dracor.org/api'"
      ],
      "metadata": {
        "id": "Uv6lTS8IayoE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plays = {\n",
        "    # 'rus': [\n",
        "    #     'bulgakov-beg',\n",
        "    #     'andreyev-mysl',\n",
        "    #     'bulgakov-zojkina-kvartira',\n",
        "    #     'chekhov-vishnevyi-sad',\n",
        "    #     'ostrovsky-bespridannitsa',\n",
        "    #     'chekhov-tri-sestry',\n",
        "    #     'ostrovsky-groza',\n",
        "    #     'turgenev-holostjak',\n",
        "    #     'gogol-revizor',\n",
        "    #     'ostrovsky-beshenye-dengi'\n",
        "    # ],\n",
        "    'span': [\n",
        "        'clarin-teresa',\n",
        "        'dicenta-juan-jose',\n",
        "        'echegaray-arrastrarse',\n",
        "        'echegaray-mancha',\n",
        "        'galdos-casandra',\n",
        "        'galdos-electra',\n",
        "        'galdos-perfecta',\n",
        "        'lorca-bernarda',\n",
        "        'lorca-bodas',\n",
        "        'lorca-rosita'\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "KdY-uoCyNVZm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "playtexts = defaultdict(dict)\n",
        "\n",
        "for corpusname, playlist in plays.items():\n",
        "  for playname in playlist:\n",
        "    endpoint = f'{API}/corpora/{corpusname}/play/{playname}/tei'\n",
        "    text = requests.get(endpoint).text\n",
        "    playtexts[corpusname][playname] = text\n",
        "    sleep(1)"
      ],
      "metadata": {
        "id": "WQN4UIu7NY19"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NAMESPACE = {'ns': 'http://www.tei-c.org/ns/1.0'}\n",
        "TURN_XPATH = '//ns:sp'\n",
        "TEXT_XPATH = './ns:p'\n",
        "LOC_XPATH = '//loc'\n",
        "\n",
        "SPACE_REGEX = re.compile(r'\\s+')\n",
        "\n",
        "def get_text_parts(p_tag):\n",
        "  parts = []\n",
        "  part_idxs = []\n",
        "\n",
        "  if p_tag.text:\n",
        "    parts.append(p_tag.text)\n",
        "  \n",
        "  for child in p_tag:\n",
        "    parts.append(child)\n",
        "    if child.tail:\n",
        "      parts.append(child.tail)\n",
        "  \n",
        "  return parts\n",
        "\n",
        "\n",
        "def compile_relevant_text(parts):\n",
        "    selected_parts = []\n",
        "    selected_part_idxs = []\n",
        "    selected_idxs_recalc = []\n",
        "    prev_end_idx = 0\n",
        "\n",
        "    for i, part in enumerate(parts):\n",
        "      if not isinstance(part, str):\n",
        "        if part.tag != 'stage':\n",
        "          preproc = SPACE_REGEX.sub(' ', part.text)\n",
        "          selected_parts.append(preproc)\n",
        "          prev_end_idx = prev_end_idx + len(preproc)\n",
        "        continue\n",
        "\n",
        "      preproc = SPACE_REGEX.sub(' ', part)\n",
        "      selected_parts.append(preproc)\n",
        "      selected_part_idxs.append(i)\n",
        "      selected_idxs_recalc.append((prev_end_idx, prev_end_idx + len(preproc)))\n",
        "      prev_end_idx = prev_end_idx + len(preproc)\n",
        "\n",
        "    return ''.join(selected_parts), selected_part_idxs, selected_idxs_recalc\n",
        "\n",
        "\n",
        "def create_elems_from_ner(text, ner_output, all_parts, selected_part_idxs, selected_idxs_recalc):\n",
        "  locations = [ent for ent in ner_output.ents if ent.type == 'LOC']\n",
        "\n",
        "  locations_by_part = [[] for _ in selected_idxs_recalc]\n",
        "  curr_part_idx = 0\n",
        "\n",
        "  for location in locations:\n",
        "    while location.start_char >= selected_idxs_recalc[curr_part_idx][1]:\n",
        "      curr_part_idx += 1\n",
        "\n",
        "    part_start, part_end = selected_idxs_recalc[curr_part_idx]\n",
        "    if part_start <= location.start_char and location.end_char < part_end:\n",
        "      locations_by_part[curr_part_idx].append(location)\n",
        "\n",
        "  for location_lst, (part_start, part_end), part_idx in zip(locations_by_part, selected_idxs_recalc, selected_part_idxs):\n",
        "    part_text = text[part_start:part_end]\n",
        "    first_tail = part_text  # for the case with no locations\n",
        "    parsed_elems = []\n",
        "    prev_end_idx = 0\n",
        "\n",
        "    for ent in location_lst:\n",
        "      ent_start = ent.start_char - part_start\n",
        "      ent_end = ent.end_char - part_start\n",
        "      loc_elem = etree.fromstring(f'<loc>{ent.text}</loc>')\n",
        "\n",
        "      if not parsed_elems:\n",
        "        first_tail = part_text[:ent_start]\n",
        "      else:\n",
        "        parsed_elems[-1].tail = part_text[prev_end_idx:ent_start]\n",
        "      \n",
        "      parsed_elems.append(loc_elem)\n",
        "      prev_end_idx = ent_end\n",
        "\n",
        "    if parsed_elems:\n",
        "      parsed_elems[-1].tail = part_text[prev_end_idx:]\n",
        "\n",
        "    if first_tail:\n",
        "      parsed_elems.insert(0, first_tail)\n",
        "    all_parts[part_idx] = parsed_elems\n",
        "\n",
        "  return all_parts\n",
        "\n",
        "\n",
        "def recompile_parts(all_parts):\n",
        "  flat_parts = []\n",
        "  for partgroup in all_parts:\n",
        "    if not isinstance(partgroup, list):\n",
        "      partgroup = [partgroup]\n",
        "\n",
        "    for i, part in enumerate(partgroup):\n",
        "      if not i and isinstance(part, str):\n",
        "        if not flat_parts:\n",
        "          flat_parts.append(part)\n",
        "        else:\n",
        "          flat_parts[-1].tail = part\n",
        "  \n",
        "      else:\n",
        "        flat_parts.append(part)\n",
        "\n",
        "  return flat_parts\n",
        "\n",
        "\n",
        "def parse_ner_in_turn(p_tags):\n",
        "  turn_parsed_elems = []\n",
        "  for p_tag in p_tags:\n",
        "    all_parts = get_text_parts(p_tag)\n",
        "    text, selected_part_idxs, selected_idxs_recalc = compile_relevant_text(all_parts)\n",
        "\n",
        "    if not text:\n",
        "      turn_parsed_elems.append([text])\n",
        "      continue\n",
        "\n",
        "    ner_output = STANZA_OBJ(text)\n",
        "    all_parts = create_elems_from_ner(text, ner_output, all_parts, selected_part_idxs, selected_idxs_recalc)\n",
        "    all_parts = recompile_parts(all_parts)\n",
        "    turn_parsed_elems.append(all_parts)\n",
        "\n",
        "  return turn_parsed_elems\n",
        "\n",
        "\n",
        "def replace_text_in_tag(parsed_texts, p_tags):\n",
        "  for parsed_elems, p_tag in zip(parsed_texts, p_tags):\n",
        "    old_children = p_tag.getchildren()\n",
        "    for child in old_children:\n",
        "      p_tag.remove(child)\n",
        "    p_tag.text = ''\n",
        "\n",
        "    elem_start_idx = 0\n",
        "    if isinstance(parsed_elems[0], str):\n",
        "      p_tag.text = parsed_elems[0]\n",
        "      elem_start_idx = 1\n",
        "    \n",
        "    for elem in parsed_elems[elem_start_idx:]:\n",
        "      p_tag.append(elem)\n",
        "\n",
        "\n",
        "def parse_ner_in_play(xml_path, xml_text):\n",
        "  tree = etree.parse(StringIO(xml_text))\n",
        "  turns = tree.xpath(TURN_XPATH, namespaces=NAMESPACE)\n",
        "  print('N turns', len(turns))\n",
        "\n",
        "  for turn in turns:\n",
        "    p_tags = turn.xpath(TEXT_XPATH, namespaces=NAMESPACE)\n",
        "    parsed_texts = parse_ner_in_turn(p_tags)\n",
        "    replace_text_in_tag(parsed_texts, p_tags)\n",
        "  \n",
        "  locs = tree.xpath(LOC_XPATH, namespaces=NAMESPACE)\n",
        "  print('N locations', len(locs))\n",
        "  \n",
        "  xml_str = etree.tostring(\n",
        "      tree,\n",
        "      pretty_print=True, \n",
        "      encoding='utf-8', \n",
        "      xml_declaration=True\n",
        "  ).decode('utf-8')\n",
        "  \n",
        "  with open(xml_path, 'w') as f:\n",
        "    f.write(xml_str)\n"
      ],
      "metadata": {
        "id": "yi9cxARka-9-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('corpus', exist_ok=True)\n",
        "\n",
        "for corpusname, corpus in playtexts.items():\n",
        "  print(corpusname)\n",
        "  os.makedirs(os.path.join('corpus', corpusname), exist_ok=True)\n",
        "  for playname, play_xml in corpus.items():\n",
        "    print(playname)\n",
        "    xml_path = os.path.join('corpus', corpusname, f'{playname}.xml')\n",
        "    parse_ner_in_play(xml_path, play_xml)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHuwIj54eRgb",
        "outputId": "1209914e-10bd-4499-f459-c198c7e7aa01"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "span\n",
            "clarin-teresa\n",
            "N turns 320\n",
            "N locations 9\n",
            "dicenta-juan-jose\n",
            "N turns 863\n",
            "N locations 7\n",
            "echegaray-arrastrarse\n",
            "N turns 1599\n",
            "N locations 51\n",
            "echegaray-mancha\n",
            "N turns 1313\n",
            "N locations 8\n",
            "galdos-casandra\n",
            "N turns 997\n",
            "N locations 20\n",
            "galdos-electra\n",
            "N turns 1588\n",
            "N locations 36\n",
            "galdos-perfecta\n",
            "N turns 1165\n",
            "N locations 34\n",
            "lorca-bernarda\n",
            "N turns 906\n",
            "N locations 3\n",
            "lorca-bodas\n",
            "N turns 876\n",
            "N locations 0\n",
            "lorca-rosita\n",
            "N turns 749\n",
            "N locations 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test that only \\<loc\\> tags have been added"
      ],
      "metadata": {
        "id": "IEdpknPl5BTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "for corpusname, corpus in playtexts.items():\n",
        "  for playname, play_xml in corpus.items():\n",
        "    xml_path = os.path.join('corpus', corpusname, f'{playname}.xml')\n",
        "    with open(xml_path) as f:\n",
        "      parsed_play = f.read()\n",
        "    \n",
        "    parsed_play = parsed_play.replace('<?xml version=\\'1.0\\' encoding=\\'utf-8\\'?>', '')\n",
        "    parsed_play = SPACE_REGEX.sub('', parsed_play)\n",
        "    parsed_play = re.sub(r'</?loc>', '', parsed_play)\n",
        "\n",
        "    play_xml = play_xml.replace(r'<?xml-stylesheet type=\"text/css\" href=\"../css/tei.css\"?>', '')\n",
        "    play_xml = SPACE_REGEX.sub('', play_xml)\n",
        "    print(playname, play_xml == parsed_play)\n",
        "\n",
        "    # sm = SequenceMatcher(None, play_xml, parsed_play)\n",
        "    # prev_a = 0\n",
        "    # prev_b = 0\n",
        "    # for match in sm.get_matching_blocks():\n",
        "    #   # print(match.size)\n",
        "    #   if match.size:\n",
        "    #     print(play_xml[prev_a-10:match.a+10], parsed_play[prev_b-10:match.b+10])\n",
        "    #     prev_a += match.size\n",
        "    #     prev_b += match.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InxKocl58pn9",
        "outputId": "b3af6890-999d-4f9f-fbf4-b87f28fed565"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clarin-teresa True\n",
            "dicenta-juan-jose True\n",
            "echegaray-arrastrarse True\n",
            "echegaray-mancha True\n",
            "galdos-casandra True\n",
            "galdos-electra True\n",
            "galdos-perfecta True\n",
            "lorca-bernarda True\n",
            "lorca-bodas True\n",
            "lorca-rosita True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jOZxnpVtvYhh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}